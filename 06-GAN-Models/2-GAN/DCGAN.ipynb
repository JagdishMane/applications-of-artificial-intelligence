{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df4ba68",
   "metadata": {},
   "source": [
    "A deep convolutional GAN (DCGAN) is more or less just a vanilla GAN with the dense layers swapped out for convolutional layers. In the following TensorFlow code, we define a DCGAN generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e6193",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_dcgan_generator(latent_dim):\n",
    "    dcgan_generator = [\n",
    "        tf.keras.Input(shape=(latent_dim,)),\n",
    "        tf.keras.layers.Dense(units=7 * 7 * 256),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Reshape(target_shape=(7, 7, 256)),\n",
    "    ] + create_generator_block(\n",
    "        filters=128, kernel_size=4, strides=2, padding=\"same\", alpha=0.2\n",
    "    ) + create_generator_block(\n",
    "        filters=128, kernel_size=4, strides=2, padding=\"same\", alpha=0.2\n",
    "    ) + [\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            filters=1,\n",
    "            kernel_size=3,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            activation=\"tanh\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Sequential(\n",
    "        layers=dcgan_generator, name=\"dcgan_generator\"\n",
    "    )\n",
    "\n",
    "\n",
    "def create_generator_block(filters, kernel_size, strides, padding, alpha):\n",
    "    return [\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "    ]\n",
    "\n",
    "\n",
    "def create_dcgan_discriminator(input_shape):\n",
    "    dcgan_discriminator = [\n",
    "        tf.keras.Input(shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=64, kernel_size=3, strides=1, padding=\"same\"\n",
    "        ),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "    ] + create_discriminator_block(\n",
    "        filters=128, kernel_size=3, strides=2, padding=\"same\", alpha=0.2\n",
    "    ) + create_discriminator_block(\n",
    "        filters=128, kernel_size=3, strides=2, padding=\"same\", alpha=0.2\n",
    "    ) + create_discriminator_block(\n",
    "        filters=256, kernel_size=3, strides=2, padding=\"same\", alpha=0.2\n",
    "    ) + [\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Sequential(\n",
    "        layers=dcgan_discriminator, name=\"dcgan_discriminator\"\n",
    "    )\n",
    "\n",
    "def create_discriminator_block(filters, kernel_size, strides, padding, alpha):\n",
    "    return [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ccbd12",
   "metadata": {},
   "source": [
    "## Conditional GAN\n",
    "- based on label.\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066d076",
   "metadata": {},
   "source": [
    "# CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9eea6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beca9a5c",
   "metadata": {},
   "source": [
    "# Super REsolutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81577f2",
   "metadata": {},
   "source": [
    "Super-resolution is the process of taking a degraded or low-resolution image and upscaling it, transforming it into a corrected, high-resolution image. Super-resolution itself has been around for a long time as part of general image processing, yet it wasnâ€™t until more recently that deep learning models were able to produce state-of-the-art results with this technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c79ac36",
   "metadata": {},
   "source": [
    "# SRGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d71f417",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
