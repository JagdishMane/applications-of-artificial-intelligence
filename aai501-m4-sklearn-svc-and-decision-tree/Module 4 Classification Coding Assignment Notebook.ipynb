{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-623ecb49dce2cff2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Classification Using Scikit-learn\n",
    "\n",
    "In this homework you will learn how to build a basic supervised learning algorithm (classification) using the most popular Python machine learning library, scikit-learn. You will follow the 3 canonical steps for building a model:\n",
    "\n",
    "1) Data preparation\n",
    "2) Model fitting\n",
    "3) Model evaluation & selection\n",
    "\n",
    "We will use the World Happiness Report (WHR) data, bringing in some additional information that will enable us to formulate a classification problem to predict categorical labels on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code cell below to import some modules and read in and preprocess the WHR data.  The last line in the code cell below returns the head of the basic WHR dataframe, to show you what is in that dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.20 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (1.20.0)\n",
      "Requirement already satisfied: pandas in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: matplotlib in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: xlrd in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\tech\\ai\\envs\\aai-501-m4\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "## Error Message: A module that was compiled using NumPy 1.x cannot be run in NumPy 2.1.3 as it may crash\n",
    "## Create a condas virtual environment aai-501-m4\n",
    "## Downgrade numpy to version 1.20\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy==1.20 pandas matplotlib xlrd scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-528dcd796b7a9020",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>LogGDP</th>\n",
       "      <th>Support</th>\n",
       "      <th>Life</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.723590</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>7.168690</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.881686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2009</td>\n",
       "      <td>4.401778</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>7.333790</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.203614</td>\n",
       "      <td>0.850035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.758381</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>7.386629</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.137630</td>\n",
       "      <td>0.706766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.831719</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>7.415019</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.175329</td>\n",
       "      <td>0.731109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.782938</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>7.517126</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>50.709263</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.775620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year  Happiness  Positive  Negative    LogGDP   Support  \\\n",
       "0  Afghanistan  2008   3.723590  0.517637  0.258195  7.168690  0.450662   \n",
       "1  Afghanistan  2009   4.401778  0.583926  0.237092  7.333790  0.552308   \n",
       "2  Afghanistan  2010   4.758381  0.618265  0.275324  7.386629  0.539075   \n",
       "3  Afghanistan  2011   3.831719  0.611387  0.267175  7.415019  0.521104   \n",
       "4  Afghanistan  2012   3.782938  0.710385  0.267919  7.517126  0.520637   \n",
       "\n",
       "        Life   Freedom  Generosity  Corruption  \n",
       "0  49.209663  0.718114    0.181819    0.881686  \n",
       "1  49.624432  0.678896    0.203614    0.850035  \n",
       "2  50.008961  0.600127    0.137630    0.706766  \n",
       "3  50.367298  0.495901    0.175329    0.731109  \n",
       "4  50.709263  0.530935    0.247159    0.775620  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "dfraw = pd.read_excel('WHR2018Chapter2OnlineData.xls', sheet_name='Table2.1')\n",
    "cols_to_include = ['country', 'year', 'Life Ladder', \n",
    "                   'Positive affect','Negative affect',\n",
    "                   'Log GDP per capita', 'Social support',\n",
    "                   'Healthy life expectancy at birth', \n",
    "                   'Freedom to make life choices', \n",
    "                   'Generosity', 'Perceptions of corruption']\n",
    "renaming = {'Life Ladder': 'Happiness', \n",
    "            'Log GDP per capita': 'LogGDP', \n",
    "            'Social support': 'Support', \n",
    "            'Healthy life expectancy at birth': 'Life', \n",
    "            'Freedom to make life choices': 'Freedom', \n",
    "            'Perceptions of corruption': 'Corruption', \n",
    "            'Positive affect': 'Positive', \n",
    "            'Negative affect': 'Negative'}\n",
    "df = dfraw[cols_to_include].rename(renaming, axis=1)\n",
    "key_vars = ['Happiness', 'LogGDP', 'Support', 'Life', 'Freedom', 'Generosity', 'Corruption', 'Positive', 'Negative']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-114766d8d149ad20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 1.\n",
    "\n",
    "First, we will augment the core WHR dataset to bring in some additional information that is included in a different worksheet.  Since this is mostly about data processing rather than machine learning, simply execute the next two code cells below.  But study each line of code and the associated comments, and then examine the head of the new dataframe named ```df2``` to understand what has been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4961999f914bb49e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country                        region\n",
       "0  Afghanistan                    South Asia\n",
       "1      Albania    Central and Eastern Europe\n",
       "2      Algeria  Middle East and North Africa\n",
       "3       Angola            Sub-Saharan Africa\n",
       "4    Argentina   Latin America and Caribbean"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data from SupportingFactors worksheet into a new dataframe dfsupp\n",
    "dfsupp = pd.read_excel('WHR2018Chapter2OnlineData.xls', sheet_name='SupportingFactors')\n",
    "\n",
    "# extract out region information from SupportingFactors dataframe\n",
    "regions = dfsupp[['country', 'Region indicator']].rename({'Region indicator': 'region'}, axis=1)\n",
    "\n",
    "# examine head of regions dataframe -- each country has an associated world region\n",
    "regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04c2e566637e8957",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>LogGDP</th>\n",
       "      <th>Support</th>\n",
       "      <th>Life</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>3.806614</td>\n",
       "      <td>0.580873</td>\n",
       "      <td>0.301283</td>\n",
       "      <td>7.419697</td>\n",
       "      <td>0.517146</td>\n",
       "      <td>50.838271</td>\n",
       "      <td>0.544895</td>\n",
       "      <td>0.118428</td>\n",
       "      <td>0.826794</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>4.988791</td>\n",
       "      <td>0.642628</td>\n",
       "      <td>0.303256</td>\n",
       "      <td>9.247059</td>\n",
       "      <td>0.723204</td>\n",
       "      <td>68.027213</td>\n",
       "      <td>0.626155</td>\n",
       "      <td>-0.105019</td>\n",
       "      <td>0.859691</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>5.555004</td>\n",
       "      <td>0.616524</td>\n",
       "      <td>0.265460</td>\n",
       "      <td>9.501728</td>\n",
       "      <td>0.804633</td>\n",
       "      <td>64.984461</td>\n",
       "      <td>0.536398</td>\n",
       "      <td>-0.208236</td>\n",
       "      <td>0.661478</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>4.420299</td>\n",
       "      <td>0.613339</td>\n",
       "      <td>0.351173</td>\n",
       "      <td>8.713935</td>\n",
       "      <td>0.737973</td>\n",
       "      <td>51.729801</td>\n",
       "      <td>0.455957</td>\n",
       "      <td>-0.077940</td>\n",
       "      <td>0.867018</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>6.406131</td>\n",
       "      <td>0.840998</td>\n",
       "      <td>0.273187</td>\n",
       "      <td>9.826051</td>\n",
       "      <td>0.906080</td>\n",
       "      <td>66.764205</td>\n",
       "      <td>0.753122</td>\n",
       "      <td>-0.154544</td>\n",
       "      <td>0.844038</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Happiness  Positive  Negative    LogGDP   Support       Life  \\\n",
       "country                                                                     \n",
       "Afghanistan   3.806614  0.580873  0.301283  7.419697  0.517146  50.838271   \n",
       "Albania       4.988791  0.642628  0.303256  9.247059  0.723204  68.027213   \n",
       "Algeria       5.555004  0.616524  0.265460  9.501728  0.804633  64.984461   \n",
       "Angola        4.420299  0.613339  0.351173  8.713935  0.737973  51.729801   \n",
       "Argentina     6.406131  0.840998  0.273187  9.826051  0.906080  66.764205   \n",
       "\n",
       "              Freedom  Generosity  Corruption                        region  \n",
       "country                                                                      \n",
       "Afghanistan  0.544895    0.118428    0.826794                    South Asia  \n",
       "Albania      0.626155   -0.105019    0.859691    Central and Eastern Europe  \n",
       "Algeria      0.536398   -0.208236    0.661478  Middle East and North Africa  \n",
       "Angola       0.455957   -0.077940    0.867018            Sub-Saharan Africa  \n",
       "Argentina    0.753122   -0.154544    0.844038   Latin America and Caribbean  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the mean values of all the WHR data for each country, averaging over all years in the dataset\n",
    "dfmean = df.groupby('country').mean().drop('year', axis=1)\n",
    "\n",
    "# merge the mean WHR data with the region information extracted previously\n",
    "df2 = pd.merge(dfmean, regions, on='country').dropna()\n",
    "\n",
    "# set the index of df2 to be the country name\n",
    "df2.set_index('country', inplace=True)\n",
    "\n",
    "# examine head of df2 dataframe -- mean WHR values for each country, along with associated regions\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3ebf9c19dc4374f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 2.\n",
    "\n",
    "This new dataframe ```df2``` is what we want to use for our machine learning task.  For each country in the dataset, we have a set of numerical values ('Happiness', 'Positive', 'Negative', etc., which are all listed in the variable ```key_vars```) and a categorical value ('region').  We would like to know if the raw numerical data are  predictive of the region.  In other words, if someone gave you a set of numerical data on Happiness, etc. for an unknown country, would you be able to predict what region of the world it might be located in?  This is an example of classification, where we will train a model based on the numerical data and the associated labels (regions).\n",
    "\n",
    "In order to proceed, we first want to extract and process some data from our ```df2``` dataframe.  We need to separate the data into two parts:\n",
    "* the region data that we want to be able to predict (we'll call it ```y```)\n",
    "* the WHR numerical data that we want to use as input to our prediction (we'll call it ```x```)\n",
    "\n",
    "Again, our goal is to build a classifier that we will train on a subset of the WHR numerical data (x) and the region data (y), so that we can predict regions from data for countries that we have not trained our model on.\n",
    "\n",
    "In the code cell below:\n",
    "* Extract the subset of ```df2``` associated with the columns in ```key_vars``` and assign it to the variable ```x```.\n",
    "* Extract the subset of ```df2``` associated with the region column, and assign it to the variable ```y```.\n",
    "* Print the shape of both `x` and `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 5% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01ec5c8a944da95a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Lets print the shape of df2 datafram\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>LogGDP</th>\n",
       "      <th>Support</th>\n",
       "      <th>Life</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>3.806614</td>\n",
       "      <td>0.580873</td>\n",
       "      <td>0.301283</td>\n",
       "      <td>7.419697</td>\n",
       "      <td>0.517146</td>\n",
       "      <td>50.838271</td>\n",
       "      <td>0.544895</td>\n",
       "      <td>0.118428</td>\n",
       "      <td>0.826794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>4.988791</td>\n",
       "      <td>0.642628</td>\n",
       "      <td>0.303256</td>\n",
       "      <td>9.247059</td>\n",
       "      <td>0.723204</td>\n",
       "      <td>68.027213</td>\n",
       "      <td>0.626155</td>\n",
       "      <td>-0.105019</td>\n",
       "      <td>0.859691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>5.555004</td>\n",
       "      <td>0.616524</td>\n",
       "      <td>0.265460</td>\n",
       "      <td>9.501728</td>\n",
       "      <td>0.804633</td>\n",
       "      <td>64.984461</td>\n",
       "      <td>0.536398</td>\n",
       "      <td>-0.208236</td>\n",
       "      <td>0.661478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>4.420299</td>\n",
       "      <td>0.613339</td>\n",
       "      <td>0.351173</td>\n",
       "      <td>8.713935</td>\n",
       "      <td>0.737973</td>\n",
       "      <td>51.729801</td>\n",
       "      <td>0.455957</td>\n",
       "      <td>-0.077940</td>\n",
       "      <td>0.867018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>6.406131</td>\n",
       "      <td>0.840998</td>\n",
       "      <td>0.273187</td>\n",
       "      <td>9.826051</td>\n",
       "      <td>0.906080</td>\n",
       "      <td>66.764205</td>\n",
       "      <td>0.753122</td>\n",
       "      <td>-0.154544</td>\n",
       "      <td>0.844038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Happiness  Positive  Negative    LogGDP   Support       Life  \\\n",
       "country                                                                     \n",
       "Afghanistan   3.806614  0.580873  0.301283  7.419697  0.517146  50.838271   \n",
       "Albania       4.988791  0.642628  0.303256  9.247059  0.723204  68.027213   \n",
       "Algeria       5.555004  0.616524  0.265460  9.501728  0.804633  64.984461   \n",
       "Angola        4.420299  0.613339  0.351173  8.713935  0.737973  51.729801   \n",
       "Argentina     6.406131  0.840998  0.273187  9.826051  0.906080  66.764205   \n",
       "\n",
       "              Freedom  Generosity  Corruption  \n",
       "country                                        \n",
       "Afghanistan  0.544895    0.118428    0.826794  \n",
       "Albania      0.626155   -0.105019    0.859691  \n",
       "Algeria      0.536398   -0.208236    0.661478  \n",
       "Angola       0.455957   -0.077940    0.867018  \n",
       "Argentina    0.753122   -0.154544    0.844038  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### From above output there are 152 rows and 10 columsn in the df2 dataframe.\n",
    "### Extract the columns assiciated with key_vars, we can read first 9 columns\n",
    "### Reference: https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html#\n",
    "x = df2.iloc[:,:9]   # iloc --> is used to select the subset of data - selection format [row_start:row_end,col_start;col_end]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Print the shape of X, it should have 152 rows and 9 columns. \n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Afghanistan                      South Asia\n",
       "Albania          Central and Eastern Europe\n",
       "Algeria        Middle East and North Africa\n",
       "Angola                   Sub-Saharan Africa\n",
       "Argentina       Latin America and Caribbean\n",
       "Name: region, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Extract the region column and assign it to varaible X.\n",
    "y = df2[\"region\"]  ### Select only region column\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Print the share of Y, it should have 152 rows and 1 column.\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The share of x is (152, 9) and the shape of y is (152,)\n"
     ]
    }
   ],
   "source": [
    "### Print the shape of X and Y together\n",
    "print(f\"The share of x is {x.shape} and the shape of y is {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c7c2b22581801780",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 3.\n",
    "\n",
    "You should see that the shape of ```x``` is (152, 9) and the shape of ```y``` is (152,).  There are 152 samples (countries), and 9 features (each of the key_vars) that we are using to make predictions.\n",
    "\n",
    "Note that the numerical data columns in ```x``` represent different quantities and have different scales. A key step in machine learning is _standardization_: the transformation of features to be on the same scale (with a mean of 0 and a standard deviation of 1). Standardization can substantially increase model accuracy, performance and interpretability.\n",
    "\n",
    "`sklearn` provides various utilities to perform standardization.  We will use one here called ```StandardScaler```, which will transform a data set so that each resulting column has zero mean and unit standard deviation.\n",
    "\n",
    "Carrying out this scaling is a little complicated if we want to maintain the basic structure of our dataframe, so we have provided the relevant code in the next code cell below.  (The code examples describing StandardScaler in the [sklearn documentation](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler) typically just extract out the numerical values in numpy arrays. For this exercise, we'd like to keep the labels together in a dataframe.)\n",
    "\n",
    "Please perform the following steps in the below graded cell:\n",
    "* Import the `StandardScaler` object\n",
    "* Create and fit a `StandardScaler` object to our dataframe ```x```\n",
    "* Create a new dataframe ```x_scaled``` that contains the scaled (transformed) data, using the column and index labels from our unscaled dataframe ```x```\n",
    "* Print out the mean and standard deviation of each column of ```x_scaled```\n",
    "* Peek at the head of the new dataframe ```x_scaled```\n",
    "\n",
    "In examining the output, check that the means of each column have been scaled to nearly zero (to within a very small tolerance) and the standard deviations have been scaled to one. Some of the very small numbers might be printed out in scientific notation, where a number like ```1.928282e-16``` means ```1.928282 * 10**(-16)```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 20% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-54c74ff720e1fb98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "### import the Standard Scaler object\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### Craete and fit a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Happiness', 'Positive', 'Negative', 'LogGDP', 'Support', 'Life',\n",
       "       'Freedom', 'Generosity', 'Corruption'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Display x columns\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a new dataframe x_scaled that contains the scaled transformed data.\n",
    "### Standardization coverts the mean to zero and Standard devaition to 1 in order to \n",
    "x_scaled = pd.DataFrame(scaler.transform(x), columns=x.columns,index=x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Happiness     1.782200e-16\n",
       "Positive      1.811417e-16\n",
       "Negative      2.337312e-16\n",
       "LogGDP        6.135443e-17\n",
       "Support      -2.337312e-16\n",
       "Life         -5.843279e-17\n",
       "Freedom       6.748987e-16\n",
       "Generosity    1.168656e-17\n",
       "Corruption    9.349247e-17\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Means for each columns in x_scaled.\n",
    "x_scaled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Happiness     1.003306\n",
       "Positive      1.003306\n",
       "Negative      1.003306\n",
       "LogGDP        1.003306\n",
       "Support       1.003306\n",
       "Life          1.003306\n",
       "Freedom       1.003306\n",
       "Generosity    1.003306\n",
       "Corruption    1.003306\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Standard deviation of x_scaled\n",
    "x_scaled.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>LogGDP</th>\n",
       "      <th>Support</th>\n",
       "      <th>Life</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>-1.443128</td>\n",
       "      <td>-1.262731</td>\n",
       "      <td>0.471370</td>\n",
       "      <td>-1.438896</td>\n",
       "      <td>-2.425953</td>\n",
       "      <td>-1.333584</td>\n",
       "      <td>-1.397623</td>\n",
       "      <td>0.735439</td>\n",
       "      <td>0.451854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>-0.360792</td>\n",
       "      <td>-0.638194</td>\n",
       "      <td>0.499009</td>\n",
       "      <td>0.054466</td>\n",
       "      <td>-0.681799</td>\n",
       "      <td>0.776161</td>\n",
       "      <td>-0.776670</td>\n",
       "      <td>-0.719736</td>\n",
       "      <td>0.632648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>0.157600</td>\n",
       "      <td>-0.902184</td>\n",
       "      <td>-0.030449</td>\n",
       "      <td>0.262588</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.402698</td>\n",
       "      <td>-1.462554</td>\n",
       "      <td>-1.391919</td>\n",
       "      <td>-0.456675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>-0.881273</td>\n",
       "      <td>-0.934399</td>\n",
       "      <td>1.170248</td>\n",
       "      <td>-0.381215</td>\n",
       "      <td>-0.556782</td>\n",
       "      <td>-1.224159</td>\n",
       "      <td>-2.077245</td>\n",
       "      <td>-0.543385</td>\n",
       "      <td>0.672914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>0.936845</td>\n",
       "      <td>1.367958</td>\n",
       "      <td>0.077797</td>\n",
       "      <td>0.527632</td>\n",
       "      <td>0.866136</td>\n",
       "      <td>0.621142</td>\n",
       "      <td>0.193546</td>\n",
       "      <td>-1.042257</td>\n",
       "      <td>0.546624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Happiness  Positive  Negative    LogGDP   Support      Life  \\\n",
       "country                                                                    \n",
       "Afghanistan  -1.443128 -1.262731  0.471370 -1.438896 -2.425953 -1.333584   \n",
       "Albania      -0.360792 -0.638194  0.499009  0.054466 -0.681799  0.776161   \n",
       "Algeria       0.157600 -0.902184 -0.030449  0.262588  0.007447  0.402698   \n",
       "Angola       -0.881273 -0.934399  1.170248 -0.381215 -0.556782 -1.224159   \n",
       "Argentina     0.936845  1.367958  0.077797  0.527632  0.866136  0.621142   \n",
       "\n",
       "              Freedom  Generosity  Corruption  \n",
       "country                                        \n",
       "Afghanistan -1.397623    0.735439    0.451854  \n",
       "Albania     -0.776670   -0.719736    0.632648  \n",
       "Algeria     -1.462554   -1.391919   -0.456675  \n",
       "Angola      -2.077245   -0.543385    0.672914  \n",
       "Argentina    0.193546   -1.042257    0.546624  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Head of new dataframe x_scaled.\n",
    "x_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-120c4b66e20c858b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 4.\n",
    "\n",
    "Now that the data has been preprocessed, we can begin with our classification analysis.  Let's start by importing some additional tools from `sklearn`.  Execute the code cell below to import:\n",
    "* the ```svm``` and ```tree``` submodules\n",
    "* the ```train_test_split``` function\n",
    "* the ```accuracy_score``` function\n",
    "\n",
    "We'll discuss in more detail below what each of these does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7b61fbfb465b7fba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e4b3a68ad0f3755",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 5.\n",
    "\n",
    "One of the convenience functions that we imported above is called ```train_test_split```.  As its name suggests, this function splits a dataset into separate training and testing sets.  The [online documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn-model-selection-train-test-split) indicates that it splits a dataset randomly, such that approximately 25% of the data winds up in the test set and the remaining 75% in the training set.  Note that the documentation is a bit confusing, since the function can take a variable number of arrays as inputs. In our case, we want to split up 2 arrays (```x_scaled``` and ```y```) into coordinated test and train sets, so that the function will return a total of 4 subarrays (```x_train, x_test, y_train, y_test```).\n",
    "\n",
    "Because ```train_test_split``` generates random splits of the input data, each time we call the function we will get a different split.  For the purposes of code development, it's useful to be able to get reproducible random numbers or random splits, as it makes debugging and model improvements much easer. This can then be relaxed once one wishes to generate statistics over many random runs.     With ```train_test_split```, this can be accomplished by using the ```random_state``` option; if specified with that state as an integer, then the same random split will be generated each time the function is called (until one changes the value of the integer).  This is known as providing a seed to the pseudo-random number generator that is used by ```train_test_split```.\n",
    "\n",
    "You may enter and execute a call to ```train_test_split``` that takes ```x_scaled``` and ```y``` as inputs, along with the optional parameter ```random_state=0```, and returns the 4 data subsets mentioned above, to be named as ```x_train```, ```x_test```, ```y_train```, ```y_test```.  The online documentation provides an example of what such a function call looks like. After the function call, print the shapes of each of the four arrays that are returned.\n",
    "\n",
    "At first pass, it makes sense to simply apply ```train_test_split()``` directly to ```x_scaled``` and ```y```; however, there is a subtle downside. Performing standardization prior to ```train_test_split()``` potentially leads to 'information leakage' whereby information about the testing dataset (its underlying distribution) is learned during the training phase. This is because the testing data distribution is used to scale the training dataset. \n",
    "\n",
    "In the code cell below, please perform ```train_test_split()``` first before applying ```StandardScaler().fit()``` *only* to the training dataset. Use that fit to transform the training dataset and the testing dataset separately. Ultimately, you should end up with the variables ```x_train_scale```, ```x_test_scale```, ```y_train``` and ```y_test``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ba571e171fc1adf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 5% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of four arrays:\n",
      "x_train == (114, 9), x_test == (38, 9), y_train == (114,), y_test == (38,)\n"
     ]
    }
   ],
   "source": [
    "### Split the data into training set (x_train, y_train) and testing sets (x_test, y_test)\n",
    "### Reference : https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation \n",
    "### test_size=0.25 splits the dataset as 75% training data and 25% testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y , test_size=0.25, random_state=0)\n",
    "\n",
    "print(\"Shapes of four arrays:\")\n",
    "print(f\"x_train == {x_train.shape}, x_test == {x_test.shape}, y_train == {y_train.shape}, y_test == {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of four arrays:\n",
      "x_train == (114, 9), x_test == (38, 9), y_train == (114,), y_test == (38,)\n"
     ]
    }
   ],
   "source": [
    "### As \"Performing standardization prior to train_test_split() potentially leads to \n",
    "### 'information leakage' whereby information about the testing dataset (its underlying distribution) \n",
    "### is learned during the training phase.\" So we split the training and test data from actuall dataset before applying StandardScaler().fit()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "print(\"Shapes of four arrays:\")\n",
    "print(f\"x_train == {x_train.shape}, x_test == {x_test.shape}, y_train == {y_train.shape}, y_test == {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "### Fit scaler only on training data.\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "### Transform test data using same scaler.\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-effebc5e9940ed25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 6.\n",
    "\n",
    "Having split our datasets, we want to first train a classifier on our training data so that we can apply it to the testing data.  One way of assessing the performance of a classifier is to compute its accuracy on the test data. That is, what fraction of the test data are correctly predicted by the classifier?  Fortunately, `sklearn` provides a built-in function named ```accuracy_score``` that carries out this computation. We imported it above, and you can read more about it in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy_score#sklearn.metrics.accuracy_score).\n",
    "\n",
    "We also imported above the ```svm``` and ```tree``` submodules from sklearn.  These provide support for Support Vector Machine (svm) and Decision Tree (tree) machine learning algorithms.  For more information, review the [Support Vector Machines (SVMs) documentation](https://scikit-learn.org/stable/modules/svm.html) and the [Decision Trees documentation](https://scikit-learn.org/stable/modules/tree.html).  Under the hood, these are very different types of algorithms.  Decision Trees try to formulate a series of yes/no questions based on the data that can distinguish the categories from one another.  SVMs, on the other hand, use techniques from geometry to find cuts through the data space to separate different categories from one another.  Understanding how these methods work in detail is beyond the scope of this exercise, but fortunately (despite the very different data structures and algorithms used internally) `sklearn` provides a uniform interface that lets us easily build these different sorts of classifiers and compare their performance.\n",
    "\n",
    "We will first consider SVMs, and then revisit the problem with Decision Trees.\n",
    "\n",
    "In the code cell below:\n",
    "* create a new ```svm.SVC()``` object and assign it to the variable ```clf1``` &mdash;  a call to ```svm.SVC()``` creates a Support Vector Classifier from the svm submodule, similar to what we did in the earlier exercise on hand-written digits\n",
    "* call the ```fit``` method on ```clf1``` with the `x_train_scale` and `y_train` training data (i.e., training the model to associate ```x_train_scale``` with ```y_train```)\n",
    "* call the ```predict``` method on ```clf1``` on the `x_test_scale` testing data and assign the result to the variable ```predictions1```, in order to make predictions for those inputs\n",
    "* call the ```accuracy_score``` function on the `y` testing data and the test predictions you generated and assign the result to the variable ```score1```\n",
    "* print the value of ```score1```\n",
    "\n",
    "The accuracy score is a fraction between 0 and 1 indicating the fraction of predictions that match the true value in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 20% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fa487bf06d148c8d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classfier is: 0.7105\n"
     ]
    }
   ],
   "source": [
    "### Create SVM classifier with default settings.\n",
    "clf1 = svm.SVC()\n",
    "\n",
    "### Fit the svm model on training data\n",
    "clf1.fit(x_train_scaled, y_train)\n",
    "\n",
    "### Predictions on test data\n",
    "predictions1 = clf1.predict(x_test_scaled)\n",
    "\n",
    "### evaluate accuracy_score\n",
    "score1 = accuracy_score(y_test, predictions1)\n",
    "\n",
    "print(f\"Accuracy of SVM classfier is: {score1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So the accuracy of SVM classifier is 71.05%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1d88f7095ce3f275",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 7.\n",
    "\n",
    "The accuracy score reported should be around 71% (0.71).  This means that approximately 29% of the countries in the test set had their regions mispredicted.  While that doesn't sound great, it could be that the WHR numerical data are not always completely predictive of region. One could imagine some countries that are \"outliers\" in a particular region, and more closely resemble other regions based on the WHR indicators.\n",
    "\n",
    "In the below code cell, please loop over all the predicted and true values in the test set, and prints out the country name and predicted region when the prediction is incorrect.  An output line like: ```Sri Lanka : South Asia -> Sub-Saharan Africa``` means that Sri Lanka is actually part of the South Asia region but was predicted to be part of Sub-Saharan Africa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 10% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Actual_Region</th>\n",
       "      <th>Predicted_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Western Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Western Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Togo</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hungary</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Western Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Southeast Asia</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tajikistan</td>\n",
       "      <td>Commonwealth of Independent States</td>\n",
       "      <td>Western Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cameroon</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Syria</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "      <td>Southeast Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>Commonwealth of Independent States</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Iran</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mauritania</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Western Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Congo (Brazzaville)</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Southeast Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>Commonwealth of Independent States</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bahrain</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Country                       Actual_Region  \\\n",
       "0                     Uganda                  Sub-Saharan Africa   \n",
       "1   Central African Republic                  Sub-Saharan Africa   \n",
       "2         Dominican Republic         Latin America and Caribbean   \n",
       "3                       Togo                  Sub-Saharan Africa   \n",
       "4                    Hungary          Central and Eastern Europe   \n",
       "5                   Tanzania                  Sub-Saharan Africa   \n",
       "6                    Nigeria                  Sub-Saharan Africa   \n",
       "7                   Ethiopia                  Sub-Saharan Africa   \n",
       "8                    Ecuador         Latin America and Caribbean   \n",
       "9                  Indonesia                      Southeast Asia   \n",
       "10                     Spain                      Western Europe   \n",
       "11                Tajikistan  Commonwealth of Independent States   \n",
       "12                  Cameroon                  Sub-Saharan Africa   \n",
       "13                     Syria        Middle East and North Africa   \n",
       "14                     Yemen        Middle East and North Africa   \n",
       "15                   Albania          Central and Eastern Europe   \n",
       "16                   Romania          Central and Eastern Europe   \n",
       "17    Bosnia and Herzegovina          Central and Eastern Europe   \n",
       "18                   Armenia  Commonwealth of Independent States   \n",
       "19                      Iran        Middle East and North Africa   \n",
       "20                Mauritania                  Sub-Saharan Africa   \n",
       "21       Congo (Brazzaville)                  Sub-Saharan Africa   \n",
       "22                   Ireland                      Western Europe   \n",
       "23               Netherlands                      Western Europe   \n",
       "24                   Ukraine  Commonwealth of Independent States   \n",
       "25                  Colombia         Latin America and Caribbean   \n",
       "26                   Bahrain        Middle East and North Africa   \n",
       "27                Luxembourg                      Western Europe   \n",
       "28              Burkina Faso                  Sub-Saharan Africa   \n",
       "\n",
       "                Predicted_region  \n",
       "0                 Western Europe  \n",
       "1                 Western Europe  \n",
       "2             Sub-Saharan Africa  \n",
       "3    Latin America and Caribbean  \n",
       "4             Sub-Saharan Africa  \n",
       "5                 Western Europe  \n",
       "6     Central and Eastern Europe  \n",
       "7    Latin America and Caribbean  \n",
       "8             Sub-Saharan Africa  \n",
       "9             Sub-Saharan Africa  \n",
       "10            Sub-Saharan Africa  \n",
       "11                Western Europe  \n",
       "12   Latin America and Caribbean  \n",
       "13    Central and Eastern Europe  \n",
       "14            Sub-Saharan Africa  \n",
       "15                Western Europe  \n",
       "16            Sub-Saharan Africa  \n",
       "17                Southeast Asia  \n",
       "18            Sub-Saharan Africa  \n",
       "19   Latin America and Caribbean  \n",
       "20                Western Europe  \n",
       "21  Middle East and North Africa  \n",
       "22                Southeast Asia  \n",
       "23            Sub-Saharan Africa  \n",
       "24   Latin America and Caribbean  \n",
       "25            Sub-Saharan Africa  \n",
       "26            Sub-Saharan Africa  \n",
       "27            Sub-Saharan Africa  \n",
       "28   Latin America and Caribbean  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_list = []\n",
    "for i in range(len(y_test)):   ### Loop over each row of y_test\n",
    "    country = y_test.index[i]  ### Gets the country from y_test\n",
    "    actual_region  = y_test.iloc[i]   ### Get the corresponding true region\n",
    "    predicted_region = predictions1[i]  ### Get the corresponding prediction region.\n",
    "\n",
    "    ### Load all incorrect predictions into incorrect list\n",
    "    if actual_region != predicted_region:\n",
    "       incorrect_list.append({\"Country\": country, \"Actual_Region\": actual_region, \"Predicted_region\": predicted_region})\n",
    "       ### print(f\"{country} : {actual_region} -> {predicted}\")\n",
    "\n",
    "### Define new dataframe for incorrect predictions.\n",
    "incorrect_df = pd.DataFrame(incorrect_list)\n",
    "incorrect_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation & selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d8cd9531f6db2bc7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 8.\n",
    "\n",
    "It is often not obvious what specific algorithm will work best for a particular dataset, so it is good to be able to conduct numerical experiments to see how different methods perform (even if we might not fully understand *why* one method might work better than another).  Because `sklearn` provides a consistent interface to very different types of underlying algorithms, it is easy to build additional classifiers to carry out these kinds of comparisons.  Here, we will build a second classifier based on Decision Trees as supported by the ```tree``` module.  Decision Tree algorithms have an element of randomness to them, so a Decision Tree can also be constructed with a specified ```random_state```  such as an integer that seeds the random number generator.  Most of what we will do here is very similar to the code you wrote a few cells up when you built a SVC classifier.\n",
    "\n",
    "In the code cell below:\n",
    "\n",
    "* Create a new ```tree.DecisionTreeClassifier()``` object with the optional argument ```random_state=0```, and assign it to the variable ```clf2``` (`clf2` stands for \"classifier number 2\", so that we can compare with ```clf1``` above).\n",
    "* Call the ```fit``` method on ```clf2``` with the `x_train_scale` and `y_train` training data (i.e., training the model to associate ```x_train_scale``` with ```y_train```).\n",
    "* Call the ```predict``` method on ```clf2``` on the `x_test_scale` testing data and assign the result to the variable ```predictions2```, in order to make predictions for those inputs.\n",
    "* Call the ```accuracy_score``` function on the `y_test` testing data and the test predictions you generated and assign the result to the variable ```score2```.\n",
    "* Print the value of ```score2```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 10% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da49b9de6d360166",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision tree classifier is: 0.7368\n"
     ]
    }
   ],
   "source": [
    "### Create Decision tree classifier object\n",
    "### Reference:\n",
    "### https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "clf2 = tree.DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "### Fit the Decision tree classifier model on training data\n",
    "clf2.fit(x_train_scaled, y_train)\n",
    "\n",
    "### Predictions on test data\n",
    "predictions2 = clf2.predict(x_test_scaled)\n",
    "\n",
    "### Evaluate accuracy_score\n",
    "score2 = accuracy_score(y_test, predictions2)\n",
    "### score2\n",
    "\n",
    "print(f\"Accuracy of Decision tree classifier is: {score2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So the accuracy of decision tree classifier is 73.68%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0d4bfe43911002ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 9.\n",
    "\n",
    "We ran two classifiers &mdash; ```clf1``` (SVM) and ```clf2``` (Decision Tree) &mdash; on a particular random `train_test_split` of the full dataset.  We can't really reach any conclusions about the relative performance of the two methods just by considering one split.  Given that ```train_test_split``` can produce different random splits, let's write a little code to compare the two classifiers for different splits.\n",
    "\n",
    "In the code cell below, write some code to do the following:\n",
    "* Write a Python `for` loop so that you can run through the loop 20 times\n",
    "* Within each pass through the loop, do the following:\n",
    "    * Call `test_train_split` on ```x``` and ```y``` to get new random instances of `x_train`, `x_test`, `y_train`, `y_test` -- in this case, you don't want to pass in a value for ```random_state``` since you want to get different random splits each time\n",
    "    * Fit StandardScaler to `x_train`, and use it to transform both `x_train` and `x_test` into `x_train_scaled` and `x_train_test`\n",
    "    * Fit each of the classifiers `clf1` and `clf2` to `x_train_scaled` and `y_train`\n",
    "    * Run predictions on each of the classifiers `clf1` and `clf2` on the `x_test_scaled` and `y_test` testing data\n",
    "    * Compute the accuracy_score of each of the two classifiers on the test data and the test predictions you generated \n",
    "    * Print the score of each classifier, as well as their difference (hint: ```print(score1, score2, score1-score2)``` to get just one line of output per iteration of the loop)\n",
    "    \n",
    "Execute the code you have written.  You should see it run through the loop 20 times, for different random data splits.  While the overall performance varies from run to run, you should probably see that the SVC classifier (```clf1```) generally performs a little bit better than the DecisionTree classifier (```clf2```).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 10% of the grade for this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4b11d4e6c2398273",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svm_score1</th>\n",
       "      <th>decision_tree_score2</th>\n",
       "      <th>score1-score2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>-0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>-0.131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>-0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>-0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.236842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>-0.026316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    svm_score1  decision_tree_score2  score1-score2\n",
       "0     0.526316              0.552632      -0.026316\n",
       "1     0.815789              0.736842       0.078947\n",
       "2     0.657895              0.605263       0.052632\n",
       "3     0.552632              0.684211      -0.131579\n",
       "4     0.578947              0.657895      -0.078947\n",
       "5     0.657895              0.552632       0.105263\n",
       "6     0.736842              0.657895       0.078947\n",
       "7     0.736842              0.736842       0.000000\n",
       "8     0.710526              0.605263       0.105263\n",
       "9     0.552632              0.578947      -0.026316\n",
       "10    0.605263              0.578947       0.026316\n",
       "11    0.684211              0.631579       0.052632\n",
       "12    0.657895              0.526316       0.131579\n",
       "13    0.684211              0.631579       0.052632\n",
       "14    0.763158              0.631579       0.131579\n",
       "15    0.657895              0.552632       0.105263\n",
       "16    0.684211              0.605263       0.078947\n",
       "17    0.684211              0.447368       0.236842\n",
       "18    0.763158              0.657895       0.105263\n",
       "19    0.605263              0.631579      -0.026316"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Define list to capture the scores.\n",
    "score_list = []\n",
    "### loop 20 times - ie Run 20 different random splits.\n",
    "for i in range(20):\n",
    "    ### Split the dataset into x_train and x_test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "    ### Fit StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train) ## Standardized training data\n",
    "    x_test_scaled = scaler.transform(x_test)   ## only transform x_test\n",
    "\n",
    "    ### Fit both classifiers svm and decision tree on scaled training data.\n",
    "    clf1.fit(x_train_scaled, y_train)\n",
    "    clf2.fit(x_train_scaled, y_train)\n",
    "\n",
    "    ### Run Prediction of each classifier using test data\n",
    "    pred1 = clf1.predict(x_test_scaled)\n",
    "    pred2 = clf2.predict(x_test_scaled)\n",
    "\n",
    "    ### Accuracy_score\n",
    "    score1 = accuracy_score(y_test, pred1)\n",
    "    score2 = accuracy_score(y_test, pred2)\n",
    "    score1score2 = score1 - score2\n",
    "    \n",
    "    ### Append scores\n",
    "    score_list.append({\"svm_score1\": score1, \"decision_tree_score2\": score2, \"score1-score2\": score1score2})\n",
    "\n",
    "###\n",
    "score_df = pd.DataFrame(score_list)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Above output shows that for most of the splits SVC classifier (clf1)  performs a little bit better than the DecisionTree classifier (clf2).***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01de5a27c9f1842e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 10.\n",
    "\n",
    "In the last code cell, you printed out the scores of the two classifiers for a small number of random splits, and examined the numerical output.  Perhaps you'd rather generate a visual summary of the relative performance of the two classifiers, for a larger number of runs.\n",
    "\n",
    "In the code cell below, copy and paste the code you wrote above and modify it to do the following:\n",
    "\n",
    "* prior to entering the `for` loop, initialize two empty lists named ```all_scores1``` and ```all_scores2``` that will be used to collect the scores of each classifier each time through the loop\n",
    "* run through the loop 1000 times instead of 20 as before\n",
    "* append the scores (```score1``` and ```score2```) to each of the lists used to contain all the scores\n",
    "* remove the print statement so that you don't get 1000 annoying print statements when you run the code\n",
    "* once the loop is finished, use the ```plt.hist``` function to plot histograms for ```all_scores1``` and ```all_scores2``` together in the same plot\n",
    "    * you can accomplish this by making two successive calls to the histogram function within the same code cell\n",
    "    * you might want to add options to change the number of bins for the histograms\n",
    "    * you should change the alpha value (opacity) of the histogram plots so that you can see both distributions, since at full opacity, the second one plotted will obscure the first one\n",
    "    * you should use the ``label`` option to label the datasets\n",
    "* After making your two calls to ```plt.hist```, you should call ``plt.legend`` to produce a legend on the plot that will identify the two datasets based on the label options that you added to your ```plt.hist``` calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 20% of the grade for this assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-28a13e824292104e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Defining empty lists\n",
    "all_scores1 = []\n",
    "all_scores2 = []\n",
    "\n",
    "### loop 1000 times - ie Run 1000 different random splits.\n",
    "for i in range(1000):\n",
    "    ### Split the dataset into x_train and x_test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "    ### Fit StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train) ## Standardized training data\n",
    "    x_test_scaled = scaler.transform(x_test)   ## only transform x_test\n",
    "\n",
    "    ### Fit both classifiers svm and decision tree on scaled training data.\n",
    "    clf1.fit(x_train_scaled, y_train)\n",
    "    clf2.fit(x_train_scaled, y_train)\n",
    "\n",
    "    ### Run Prediction of each classifier using test data\n",
    "    pred1 = clf1.predict(x_test_scaled)\n",
    "    pred2 = clf2.predict(x_test_scaled)\n",
    "\n",
    "    ### Accuracy_score\n",
    "    score1 = accuracy_score(y_test, pred1)\n",
    "    score2 = accuracy_score(y_test, pred2)\n",
    "    \n",
    "    ### Append scores\n",
    "    all_scores1.append(score1)\n",
    "    all_scores2.append(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(all_scores1, bins=20, alpha=0.6, label='SVM Classifier')\n",
    "plt.hist(all_scores2, bins=20, alpha=0.6, label='Decision Tree Classifier')\n",
    "plt.legend()\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SVM and Decision Tree Classifier Accuracy Distribution - 1000 splits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram Observations:**\n",
    "\n",
    "1. For 1000 differents splits, SVM Classifier perform better than Decision tree classifier.\n",
    "2. SVM accuracy is centered around 0.63 to 0.67 and narrow spread.\n",
    "3. Decision Tree classifier accuracy is centered around 0.59 to 0.61.\n",
    "4. Also Decision Tree classifier shows wider spread compared to SVM. That mean less conistancy in accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5096838c0f9fe754",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Just scratching the surface...\n",
    "\n",
    "This is just the start of what you can do with scikit-learn.  It is clear from the documentation that there are many different methods and algorithms for classification that are supported by the package, as well as different ways of optimizing and assessing the performance of different algorithms.  If you are motivated to explore further, feel free to continue below by opening more code cells and using the scikit-learn documentation to guide some further exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to Submit?\n",
    "\n",
    "Please run your Jupyter Notebook first to generate outputs for each code cell and then export the report as a HTML file by clicking the following links (File -> Download as -> HTML (.html)). Please zip both the Jupyter Notebook and the HTML file and submit your ZIP file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aai-501-m4]",
   "language": "python",
   "name": "conda-env-aai-501-m4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
